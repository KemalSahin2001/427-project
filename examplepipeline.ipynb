{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "586fb8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_files.llm_pipeline.twcs_processor as processor\n",
    "import pandas as pd\n",
    "import json\n",
    "from Notebooks.VectorDBStructure.query import query_similar\n",
    "from py_files.llm_pipeline.reranker import CrossEncoderReranker\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33da006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "from py_files.CONFIG import ENDBOT_PROMPT\n",
    "\n",
    "# Load environment variables from .env file\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set OpenAI API key\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8c8374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I accidentally booked the same flight twice—VX666 and VX667. Please refund one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a657cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = processor.TWCSProcessor._clean_single(user_input)\n",
    "user_input_processed = processor.TWCSProcessor._convert_to_conversation(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a123ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the user input to a pandas dataframe\n",
    "user_input_df = pd.DataFrame([[user_input,user_input_processed]], columns=['cleaned_conversation','structured_conversations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4863783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_conversation</th>\n",
       "      <th>structured_conversations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I accidentally booked the same flight twiceVX6...</td>\n",
       "      <td>{'conversation': [{'role': 'Customer', 'messag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                cleaned_conversation  \\\n",
       "0  I accidentally booked the same flight twiceVX6...   \n",
       "\n",
       "                            structured_conversations  \n",
       "0  {'conversation': [{'role': 'Customer', 'messag...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33c8d228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 16:20:49,610 [INFO] LLMExtractor: Loaded data – 1 rows\n",
      "2025-06-16 16:20:49,611 [INFO] LLMExtractor: STEP 1 – Extracting issue‑types, products, services\n",
      "LLM steps:   0%|          | 0/1 [00:00<?, ?it/s]2025-06-16 16:20:50,352 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM steps: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "LLM steps:   0%|          | 0/1 [00:00<?, ?it/s]2025-06-16 16:20:51,269 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM steps: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "LLM steps:   0%|          | 0/1 [00:00<?, ?it/s]2025-06-16 16:20:51,646 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM steps: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n",
      "2025-06-16 16:20:51,649 [INFO] LLMExtractor: STEP 2 – Packing entities into single JSON field\n",
      "LLM steps: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "2025-06-16 16:20:51,651 [INFO] LLMExtractor: STEP 3 – Extracting relationships (RDF triples)\n",
      "LLM steps:   0%|          | 0/1 [00:00<?, ?it/s]2025-06-16 16:20:54,319 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM steps: 100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n"
     ]
    }
   ],
   "source": [
    "from py_files.llm_pipeline.llm_extractor import LLMExtractor\n",
    "pipe = LLMExtractor(dataframe = user_input_df)\n",
    "\n",
    "# only products / issue-types / services\n",
    "df1 = pipe.extract_entities()\n",
    "\n",
    "# pack them into a single JSON field\n",
    "df2 = pipe.process_entities_json()\n",
    "\n",
    "# create RDF triples\n",
    "df3 = pipe.extract_relationships()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da42bbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 16:20:54,329 [INFO] sentence_transformers.SentenceTransformer: Use pytorch device_name: cuda\n",
      "2025-06-16 16:20:54,329 [INFO] sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "from Notebooks.VectorDBStructure.db_structure import DatabaseStructure\n",
    "\n",
    "db = DatabaseStructure()\n",
    "\n",
    "cleaned_conversations = user_input_processed\n",
    "entities = df3['entities'].values[0]\n",
    "relationship = df3['relationship'].values[0]\n",
    "cleaned_conversation = df3['cleaned_conversation'].values[0]\n",
    "\n",
    "fixed_relationships = db.fix_relationships(relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8b9d200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e55735631c4f7ca3868dbd592f3a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ca987f899648eb94826571e3922d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding = db.text_to_embedding(cleaned_conversation, entities, fixed_relationships).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdc8e167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 16:20:56,727 [INFO] elastic_transport.transport: GET http://localhost:9200/chat_embeddings/_mapping [status:200 duration:0.003s]\n",
      "2025-06-16 16:20:56,743 [INFO] elastic_transport.transport: POST http://localhost:9200/chat_embeddings/_search [status:200 duration:0.015s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize the reranker\n",
    "reranker = CrossEncoderReranker(top_k=50)\n",
    "\n",
    "# Step 2: Query Elastic and get hits\n",
    "hits = query_similar(embedding, k=50)\n",
    "\n",
    "# Step 3: Extract conversation candidates\n",
    "candidates = [hit[\"_source\"][\"Conversation_History\"][\"conversation\"] for hit in hits]\n",
    "\n",
    "# Step 4: Rerank with cross-encoder\n",
    "reranked = reranker.rerank(user_input, candidates)\n",
    "\n",
    "# Step 5: Create a mapping: conversation -> (score, rank)\n",
    "score_rank_map = {\n",
    "    conv: (score, rank + 1)  # rank is 1-based\n",
    "    for rank, (conv, score) in enumerate(reranked)\n",
    "}\n",
    "\n",
    "# Step 6: Construct final rows with rank\n",
    "rows = []\n",
    "for hit in hits:\n",
    "    src = hit[\"_source\"]\n",
    "    conv = src[\"Conversation_History\"][\"conversation\"]\n",
    "    score, rank = score_rank_map.get(conv, (0.0, None))  # Not reranked if not in top_k\n",
    "\n",
    "    rows.append({\n",
    "        \"prompt\": user_input,\n",
    "        \"id\": hit[\"_id\"],\n",
    "        \"similarity_score\": hit[\"_score\"],\n",
    "        \"rerank_score\": score,\n",
    "        \"rerank_rank\": rank,\n",
    "        \"ChatID\": src[\"ChatID\"],\n",
    "        \"Company_name\": src[\"Company_name\"],\n",
    "        \"Conversation_History\": conv,\n",
    "        \"Entities\": json.dumps(src[\"Entities\"]),\n",
    "        \"Relationships\": json.dumps(src[\"Relationships\"])\n",
    "    })\n",
    "\n",
    "# Step 7: Create DataFrame and optionally sort by rerank_rank\n",
    "reranked_qa = pd.DataFrame(rows).sort_values(by=\"rerank_rank\", na_position=\"last\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "952c876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "reranked_qa[[\"sim_norm\", \"rerank_norm\"]] = scaler.fit_transform(\n",
    "    reranked_qa[[\"similarity_score\", \"rerank_score\"]].fillna(0)\n",
    ")\n",
    "reranked_qa[\"hybrid_score\"] = 0.7 * reranked_qa[\"sim_norm\"] + 0.3 * reranked_qa[\"rerank_norm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6336fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_candidates = reranked_qa.sort_values(by=\"hybrid_score\", ascending=False).head(10)\n",
    "\n",
    "seen_combinations = set()\n",
    "filtered_rows = []\n",
    "\n",
    "for _, row in top_candidates.iterrows():\n",
    "    key = (row[\"Entities\"], row[\"Relationships\"])\n",
    "    if key not in seen_combinations:\n",
    "        filtered_rows.append(row)\n",
    "        seen_combinations.add(key)\n",
    "    if len(filtered_rows) == 5:\n",
    "        break\n",
    "\n",
    "top5_df = pd.DataFrame(filtered_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e3326d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>id</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>rerank_score</th>\n",
       "      <th>rerank_rank</th>\n",
       "      <th>ChatID</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Conversation_History</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Relationships</th>\n",
       "      <th>sim_norm</th>\n",
       "      <th>rerank_norm</th>\n",
       "      <th>hybrid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I accidentally booked the same flight twiceVX6...</td>\n",
       "      <td>MM3LeJcB1089BAnsM783</td>\n",
       "      <td>1.656683</td>\n",
       "      <td>-7.155315</td>\n",
       "      <td>27</td>\n",
       "      <td>1210</td>\n",
       "      <td>VirginAmerica</td>\n",
       "      <td>Customer Better hope I make it in time if not ...</td>\n",
       "      <td>{\"products\": [], \"services\": [], \"issue_types\"...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.490571</td>\n",
       "      <td>-0.225382</td>\n",
       "      <td>2.375785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I accidentally booked the same flight twiceVX6...</td>\n",
       "      <td>rs3LeJcB1089BAnsMr2C</td>\n",
       "      <td>1.622004</td>\n",
       "      <td>-5.170570</td>\n",
       "      <td>12</td>\n",
       "      <td>824</td>\n",
       "      <td>VirginAmerica</td>\n",
       "      <td>Customer Thank you for being amazing rebooking...</td>\n",
       "      <td>{\"products\": [\"ticket\"], \"services\": [], \"issu...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2.132549</td>\n",
       "      <td>0.757770</td>\n",
       "      <td>1.720116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I accidentally booked the same flight twiceVX6...</td>\n",
       "      <td>5s3LeJcB1089BAnsM8DO</td>\n",
       "      <td>1.614958</td>\n",
       "      <td>-4.878383</td>\n",
       "      <td>11</td>\n",
       "      <td>1648</td>\n",
       "      <td>VirginAmerica</td>\n",
       "      <td>Customer without a doubt the worse airline to ...</td>\n",
       "      <td>{\"products\": [], \"services\": [\"VirginAmerica r...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.856619</td>\n",
       "      <td>0.902506</td>\n",
       "      <td>1.570385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I accidentally booked the same flight twiceVX6...</td>\n",
       "      <td>bM3LeJcB1089BAnsM8DO</td>\n",
       "      <td>1.581204</td>\n",
       "      <td>0.448395</td>\n",
       "      <td>1</td>\n",
       "      <td>1526</td>\n",
       "      <td>VirginAmerica</td>\n",
       "      <td>Customer you guys are so incompetent and ridic...</td>\n",
       "      <td>{\"products\": [\"VirginAmerica flight vx1960\", \"...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.534825</td>\n",
       "      <td>3.541148</td>\n",
       "      <td>1.436722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I accidentally booked the same flight twiceVX6...</td>\n",
       "      <td>Fs3LeJcB1089BAnsMLui</td>\n",
       "      <td>1.606600</td>\n",
       "      <td>-4.616110</td>\n",
       "      <td>6</td>\n",
       "      <td>160</td>\n",
       "      <td>VirginAmerica</td>\n",
       "      <td>Customer cancelled flight entire plane full of...</td>\n",
       "      <td>{\"products\": [\"flight\", \"Ticket attendants\", \"...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.529319</td>\n",
       "      <td>1.032424</td>\n",
       "      <td>1.380251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt                    id  \\\n",
       "26  I accidentally booked the same flight twiceVX6...  MM3LeJcB1089BAnsM783   \n",
       "11  I accidentally booked the same flight twiceVX6...  rs3LeJcB1089BAnsMr2C   \n",
       "10  I accidentally booked the same flight twiceVX6...  5s3LeJcB1089BAnsM8DO   \n",
       "0   I accidentally booked the same flight twiceVX6...  bM3LeJcB1089BAnsM8DO   \n",
       "5   I accidentally booked the same flight twiceVX6...  Fs3LeJcB1089BAnsMLui   \n",
       "\n",
       "    similarity_score  rerank_score  rerank_rank ChatID   Company_name  \\\n",
       "26          1.656683     -7.155315           27   1210  VirginAmerica   \n",
       "11          1.622004     -5.170570           12    824  VirginAmerica   \n",
       "10          1.614958     -4.878383           11   1648  VirginAmerica   \n",
       "0           1.581204      0.448395            1   1526  VirginAmerica   \n",
       "5           1.606600     -4.616110            6    160  VirginAmerica   \n",
       "\n",
       "                                 Conversation_History  \\\n",
       "26  Customer Better hope I make it in time if not ...   \n",
       "11  Customer Thank you for being amazing rebooking...   \n",
       "10  Customer without a doubt the worse airline to ...   \n",
       "0   Customer you guys are so incompetent and ridic...   \n",
       "5   Customer cancelled flight entire plane full of...   \n",
       "\n",
       "                                             Entities Relationships  sim_norm  \\\n",
       "26  {\"products\": [], \"services\": [], \"issue_types\"...            []  3.490571   \n",
       "11  {\"products\": [\"ticket\"], \"services\": [], \"issu...            []  2.132549   \n",
       "10  {\"products\": [], \"services\": [\"VirginAmerica r...            []  1.856619   \n",
       "0   {\"products\": [\"VirginAmerica flight vx1960\", \"...            []  0.534825   \n",
       "5   {\"products\": [\"flight\", \"Ticket attendants\", \"...            []  1.529319   \n",
       "\n",
       "    rerank_norm  hybrid_score  \n",
       "26    -0.225382      2.375785  \n",
       "11     0.757770      1.720116  \n",
       "10     0.902506      1.570385  \n",
       "0      3.541148      1.436722  \n",
       "5      1.032424      1.380251  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c95716ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conversation(text: str) -> List[Dict[str, str]]:\n",
    "    lines = text.split(\"\\n\")\n",
    "    parsed = []\n",
    "    for line in lines:\n",
    "        lower = line.lower()\n",
    "        if lower.startswith(\"customer\"):\n",
    "            role = \"Customer\"\n",
    "            msg = line[len(\"Customer\"):].strip()\n",
    "        elif lower.startswith(\"company\"):\n",
    "            role = \"Company\"\n",
    "            msg = line[len(\"Company\"):].strip()\n",
    "        else:\n",
    "            # fallback: use last role or unknown\n",
    "            role = \"Customer\" if not parsed else parsed[-1][\"role\"]\n",
    "            msg = line.strip()\n",
    "        if msg:\n",
    "            parsed.append({\"role\": role, \"message\": msg})\n",
    "    return parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36022d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_payload_per_qa(df_top5, query: str) -> str:\n",
    "    results = []\n",
    "    for _, row in df_top5.iterrows():\n",
    "        conv = row[\"Conversation_History\"]\n",
    "\n",
    "        if isinstance(conv, str):\n",
    "            try:\n",
    "                conv_json = json.loads(conv)\n",
    "                conversation = conv_json  # Already parsed\n",
    "            except:\n",
    "                conversation = parse_conversation(conv)\n",
    "        else:\n",
    "            conversation = conv\n",
    "\n",
    "        try:\n",
    "            intents = json.loads(row[\"Entities\"])\n",
    "        except:\n",
    "            intents = {}\n",
    "\n",
    "        try:\n",
    "            relationships = json.loads(row[\"Relationships\"])\n",
    "        except:\n",
    "            relationships = []\n",
    "\n",
    "        results.append({\n",
    "            \"company_name\": row[\"Company_name\"],\n",
    "            \"conversation\": conversation,\n",
    "            \"intents\": intents,\n",
    "            \"relationships\": relationships\n",
    "        })\n",
    "\n",
    "    full_payload = {\n",
    "        \"query\": query.strip(),\n",
    "        \"retrieved_answers\": results\n",
    "    }\n",
    "\n",
    "    return json.dumps(full_payload, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da488c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = build_payload_per_qa(\n",
    "    df_top5=top5_df.sort_values(by=\"hybrid_score\", ascending=False).head(5),\n",
    "    query=user_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7523e1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 16:20:58,167 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry to hear about your situation; please contact our reservations team at 1-877-359-8474 for assistance with your refund request.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": ENDBOT_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": payload}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    top_p=0.95\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c48fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

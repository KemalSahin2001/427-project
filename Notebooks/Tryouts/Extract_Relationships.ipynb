{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = \"..\\\\..\\\\Data\\processed\\Intents\\ExtractedIntents_UniqueCount-10_time-20241222-1556.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Extract the structured conversations and intents\n",
    "structured_conversations = data['structured_conversations']\n",
    "intents = data['intents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6767336a1741d2961757db102b85ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the Llama pipeline\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relationships(conversation_text, entities):\n",
    "    \"\"\"\n",
    "    Extract relationships between entities and intents from structured conversation text.\n",
    "    \"\"\"\n",
    "    # Define the system prompt for Llama\n",
    "    system_prompt = \"\"\"\n",
    "    You are a relationship extraction model. Your task is to identify meaningful relationships between entities and intents in the provided structured conversations. \n",
    "    The relationships are represented as RDF triples (subject, predicate, object). \n",
    "    Common relationships include:\n",
    "    - hasIssue: Links a product/service to an issue.\n",
    "    - appliesTo: Links an issue to an intent.\n",
    "    - resolvesWith: Links an issue to a resolution.\n",
    "    - providedBy: Links a product/service to a provider.\n",
    "    \n",
    "    Provide your response in this format:\n",
    "    [\n",
    "        {\"subject\": \"<entity>\", \"predicate\": \"<relationship>\", \"object\": \"<entity or intent>\"}\n",
    "    ]\n",
    "\n",
    "    What you MUST do:\n",
    "    - YOU HAVE TO USE OUTPUT STRUCTURE AND DO NOT ADD ANY EXTRA TEXT BEFORE OR AFTER THE OUTPUT STRUCTURE.\n",
    "    - JUST ANSWER WITH OUTPUT STRUCTURE.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create messages for the pipeline\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            Here is the conversation text: '{conversation_text}'.\n",
    "            Extracted entities and intents: {entities}.\n",
    "            Identify relationships between these elements and provide RDF triples.\n",
    "            \"\"\",\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    # Generate relationships using Llama pipeline\n",
    "    output = pipe(messages, max_new_tokens=256)\n",
    "\n",
    "    # Extract and return the generated content\n",
    "    return output[0][\"generated_text\"][-1].get(\"content\", \"\") if output else \"No relationships found.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    conversation_text = row['structured_conversations']\n",
    "    entities = row['intents']  # Assuming 'intents' contains the extracted entities\n",
    "    \n",
    "    # Extract relationships\n",
    "    relationships = extract_relationships(conversation_text, entities)\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\"conversation\": conversation_text, \"entities\": entities, \"relationships\": relationships})\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\"subject\": \"sprintcare\", \"predicate\": \"providedBy\", \"object\": \"Company_name\"},\n",
      "    {\"subject\": \"sprintcare\", \"predicate\": \"hasIssue\", \"object\": \"poor service\"},\n",
      "    {\"subject\": \"poor service\", \"predicate\": \"appliesTo\", \"object\": \"Complaint\"},\n",
      "    {\"subject\": \"poor service\", \"predicate\": \"appliesTo\", \"object\": \"Request for Assistance\"},\n",
      "    {\"subject\": \"account review\", \"predicate\": \"appliesTo\", \"object\": \"Request for Assistance\"}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(results[0].get(\"relationships\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save results to a JSON file\n",
    "# import json\n",
    "\n",
    "# output_path = \"relationships_output.json\"\n",
    "# with open(output_path, \"w\") as f:\n",
    "#     json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
